{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadbag98/DL_HW/blob/main/HW3/ultra_wide_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XWkt5i7t9BE3"
      },
      "outputs": [],
      "source": [
        "#Necessary imports\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d8pij4Hk-h5-"
      },
      "outputs": [],
      "source": [
        "#Data preparation functions\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "class HousingDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "  Prepare the California Housing dataset for regression\n",
        "  Code was taken from https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-create-a-neural-network-for-regression-with-pytorch.md\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, X, y, scale_data=True, normalize_data=True):\n",
        "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
        "            # Apply scaling if necessary\n",
        "            if scale_data:\n",
        "                X = StandardScaler().fit_transform(X)\n",
        "            if normalize_data:\n",
        "              #data is normalized since this is assumed for the shallow network\n",
        "                X = Normalizer().fit_transform(X)\n",
        "            self.X = torch.from_numpy(X)\n",
        "            self.y = torch.from_numpy(y).view(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "\n",
        "def get_california_dataset():\n",
        "    X, y = fetch_california_housing(return_X_y=True)\n",
        "    dataset = HousingDataset(X , y)\n",
        "    num_samples = X.shape[0]\n",
        "    train_size = int(num_samples * 0.01)\n",
        "    test_size = num_samples - train_size\n",
        "    train_set, test_set = random_split(dataset, [train_size, test_size])\n",
        "    # setting batch sizes equal to set size in order to run full batch GD\n",
        "    train_loader = DataLoader(train_set, batch_size=train_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_set, batch_size=train_size, shuffle=False)\n",
        "    in_dim = X.shape[1]\n",
        "    out_dim = 1 if len(y.shape) == 1 else y.shape[1]\n",
        "    return train_loader, test_loader, in_dim, out_dim "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ESymzamcRQVd"
      },
      "outputs": [],
      "source": [
        "#Training and testing epochs for the NN model\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def NN_epoch(net: nn.Module,\n",
        "                optim: torch.optim.Optimizer,\n",
        "                criterion: nn.Module,\n",
        "                train_loader: torch.utils.data.DataLoader):\n",
        "\n",
        "  net.to(device)\n",
        "  for data in train_loader:\n",
        "        inputs, targets = data\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optim.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs.view(-1), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "  return net(inputs) #This suits in our case of full-batch GD\n",
        "\n",
        "\n",
        "def test_epoch(net: nn.Module,\n",
        "               criterion: nn.Module,\n",
        "               test_loader: torch.utils.data.DataLoader):\n",
        "    epoch_loss = 0.0\n",
        "    net.zero_grad()\n",
        "    for data in test_loader:\n",
        "        inputs, targets = data\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lSWpXierem8Y"
      },
      "outputs": [],
      "source": [
        "# An epoch of GD by the given formula\n",
        "\n",
        "def NTK_epoch(u : torch.Tensor,\n",
        "              train_loader: torch.utils.data.DataLoader,\n",
        "              lr : float):\n",
        "  for data in train_loader: #single iteration\n",
        "    X, y = data\n",
        "  X, y = X.to(device), y.to(device)\n",
        "  #removed since setting shown in class assumes ||x||==1\n",
        "  # normalized_X = F.normalize(X)  \n",
        "  # H = (1/torch.pi)(X@X.t())*(torch.pi-torch.acos(normalized_X@normalized_X.t()))\n",
        "  H = (0.5/torch.pi)*(X@X.t())*(torch.pi-torch.acos(X@X.t()).nan_to_num())\n",
        "  u_dt = -H@(u-y)\n",
        "  u = u+lr*u_dt\n",
        "  return u\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gQ_7zlqtfyYP"
      },
      "outputs": [],
      "source": [
        "class ShallowNN(nn.Module):\n",
        "\n",
        "  def __init__(self,init_weight,GPU=True):\n",
        "    super(ShallowNN,self).__init__()\n",
        "    self.in_dim = init_weight.shape[1]\n",
        "    self.hidden_width = init_weight.shape[0]\n",
        "    self.out_dim = 1\n",
        "    self.layers = nn.ModuleList()\n",
        "    hidden_layer = nn.Linear(self.in_dim,self.hidden_width,\n",
        "                                  bias=False,dtype=torch.float64)\n",
        "    hidden_layer.weight.data = init_weight.double()\n",
        "    self.layers.append(hidden_layer)\n",
        "    relu = nn.ReLU()\n",
        "    self.layers.append(relu)\n",
        "    # output weights of 1 or -1, with equal prob. to each\n",
        "    output_weights = (2*torch.bernoulli(torch.empty(self.hidden_width).\n",
        "                                             uniform_(0,1))-1).double()\n",
        "    output_layer = nn.Linear(self.hidden_width,1,bias=False,dtype=torch.float64)\n",
        "    output_layer.weight.data = output_weights\n",
        "    self.layers.append(output_layer)                \n",
        "                              \n",
        "    \n",
        "\n",
        "    \n",
        "  def forward(self,x):\n",
        "    for layer in self.layers:\n",
        "      layer.double()\n",
        "      x = layer(x)\n",
        "    return (1/np.sqrt(self.hidden_width))*x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR_syiIZA-90"
      },
      "outputs": [],
      "source": [
        "def experiment(epochs = 20000 , lr= 1e-4 ,widths = [10**i for i in range(1,6,2)]):\n",
        "  dist = np.zeros((len(widths),epochs))\n",
        "  train_loader, test_loader, in_dim, out_dim  = get_california_dataset()\n",
        "  for i in tqdm(range(len(widths))):\n",
        "    hidden_width = widths[i]\n",
        "    init_weights = torch.normal(mean=0.0,std=1.0,size=(hidden_width,in_dim))\n",
        "    init_weights.to(device)\n",
        "    net = ShallowNN(init_weights)\n",
        "    net = net.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optim = torch.optim.SGD(net.parameters(),lr)\n",
        "    for data in train_loader:\n",
        "      X, y = data\n",
        "    X = X.to(device)\n",
        "    u_ntk = net(X)\n",
        "    for e in tqdm(range(epochs)):\n",
        "      u_net = NN_epoch(net, optim, criterion, train_loader)\n",
        "      u_ntk = NTK_epoch(u_ntk,train_loader,lr)\n",
        "      dist[i][e] = torch.linalg.norm(u_net-u_ntk).item()\n",
        "  return dist\n",
        "    \n",
        "    \n",
        "\n",
        "dist = experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qn4xEOsL40mz"
      },
      "outputs": [],
      "source": [
        "def plot_result(results: np.ndarray, path: str = 'HW3', widths = [10**i for i in range(1,6,2)]):\n",
        "    \"\"\"\n",
        "    Plots value of results for each network depth as a function of epoch\n",
        "    :param results: Dictionary with keys that are network depths, and values that\n",
        "                    are dictionaries of value name (i.e. \"Train Loss\") to list of values\n",
        "    :param value_to_plot: Specific result to plot\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    for i, width in enumerate(widths):\n",
        "        value_to_epoch = results[i]\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=np.arange(1, len(value_to_epoch)+1), y=value_to_epoch, mode='lines+markers', name=\"W=\"+str(width))\n",
        "        )\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Epoch #\",\n",
        "        yaxis_title=\"Value of Distance Between Net and NTK\"\n",
        "    )\n",
        "    fig.show()\n",
        "    # fig.savefig(\"u_dist_plot.png\")\n",
        "    # files.download(\"u_dist_plot.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWbKj60m7Z1q"
      },
      "outputs": [],
      "source": [
        "plot_result(dist)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ultra_wide_experiment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgnxjXnGqAKWA50apoxvMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}